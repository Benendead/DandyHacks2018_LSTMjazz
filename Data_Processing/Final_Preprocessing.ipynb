{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Preprocessing",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "4MIWGuuTyDdh"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benned-H/LSTMjazz/blob/master/Data_Processing/Final_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2AMvZWMG5dyK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Author(s) | Year | Models Used | Music | Encoding | Quantization | Future work | Code/Examples\n",
        "--- | ---\n",
        "Eck | 2002 | LSTM | Melody + chords | 13 melody, 12 chord 1/0 | 2 per beat | N/A | [Ex](https://web.archive.org/web/20190104192500/http://people.idsia.ch/~juergen/blues/)\n",
        "Bickerman | 2010 | DBN | Chords -> jazz licks | 18 melody (12 pitch, 4 8va), 12 chord | 12 per beat | Melodies avoid triplets | [Code](https://sourceforge.net/projects/rbm-provisor/)\n",
        "Choi | 2016 | char-RNN, word-RNN | Jazz chord progressions | Note chars, Chord words | 1 per beat | N/A | [Code](https://github.com/keunwoochoi/lstm_real_book)\n",
        "Lackner | 2016 | LSTM | Melody given chords | 24 melody, 12 chord 1/0 | 4 per beat | Larger dataset | [Ex](https://konstilackner.github.io/LSTM-RNN-Melody-Composer-Website/)\n",
        "Agarwala | 2017 | Seq2Seq, char-RNN | Melodies | ABC char -> embeddings | None; ABC notation | N/A | [Code](https://github.com/yinoue93/CS224N_proj)\n",
        "Brunner | 2017 | 2 LSTMs | Chords -> polyphonic piano | 48 melody, 50 chord embeddings | 2 per beat | Encoding polyphonic sustain, genre metadata | N/A\n",
        "Hilscher | 2018 | char-RNN | Polyphonic piano | 1/0 on/off vectors | 4 per beat | More keys/data, text pattern matching | [Ex](https://yellow-ray.de/~moritz/midi_rnn/examples.html)"
      ]
    },
    {
      "metadata": {
        "id": "_VxmZvUCTmc_",
        "colab_type": "code",
        "outputId": "ae4a40f1-2d5b-45f0-cd8f-2f647db6fbfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MFlwt2tyUTsb",
        "colab_type": "code",
        "outputId": "2e139d4c-612b-4b86-a5af-f3d3c8c6b773",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m1YoQIYVTqar",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('gdrive/My Drive/Datasets')\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mFY2-lBNUfiu",
        "colab_type": "code",
        "outputId": "755603fb-639a-462e-9f58-c055a964ed39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# We have all of our data in these subfolders.\n",
        "len(glob.glob(\"*/*.csv\"))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "4MIWGuuTyDdh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Additional Data Formatting Considerations"
      ]
    },
    {
      "metadata": {
        "id": "A_Lh6E9d1Mq8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In the work of [Brunner et al.](https://arxiv.org/abs/1711.07682) (2017), their LSTM received vectors of piano rolls with these appended features:\n",
        "1. Embedded chord vector of the next time step. (Current chord)\n",
        "2. Embedded chord vector of the chord following that chord.\n",
        "3. A binary counter from 0 to 7 each bar.\n",
        "\n",
        "Because my timesteps are much finer, I'd alter these features to the following:\n",
        "1. \"Current\" embedded chord vector for this timestep.\n",
        "2. Embedded chord vector of the chord following that chord.\n",
        "3. See below for different timing bit vector."
      ]
    },
    {
      "metadata": {
        "id": "Ydoa7p-R1poJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In my case, I would need to count to 48 OR simplify the bits a bit to give information only about on-beat, off-beat, sixteenth, and triplet information. What about:\n",
        "\n",
        "---\n",
        "Bit 8 | Bit 7 | Bit 6 | Bit 5 | Bit 4 | Bit 3 | Bit 2 | Bit 1\n",
        "--- | ---\n",
        "Third triplet | Second triplet | Any triplet | On any down-beat | On any half-note | On-beat | On any 8th | On any 16th\n",
        "Offset % 12 = 8 | Offset % 12 = 4 | Offset % 4 = 0 | Offset % 48 = 0 | Offset % 24 = 0 | Offset % 12 = 0 | Offset % 6 = 0  | Offset % 3 = 0"
      ]
    },
    {
      "metadata": {
        "id": "YK-UYTQO24QT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Bit 7 | Bit 6 | Bit 5 | Bit 4 | Bit 3 | Bit 2 | Bit 1\n",
        "--- | ---\n",
        "Third triplet | Second triplet | On-beat | On any 8th | On any 16th | Count 4 beats Bit 2 | Count 4 beats Bit 1\n",
        "Offset % 12 = 8 | Offset % 12 = 4 | Offset % 12 = 0 | Offset % 6 = 0 | Offset % 3 = 0 | ???  | ???\n",
        "\n",
        "To be clear, these features give the LSTM an easier job knowing when to change notes. To that end, I'd argue that such assistance might normally come from a rhythm section, and it's not inherently \"unfair\" information to give the system. What it might cause is a much clearer bias towards on-beat or on-eighth (etc.) notes, but balancing temperature and over-fitting can hopefully alleviate these concerns."
      ]
    },
    {
      "metadata": {
        "id": "nTf6At9t7WG4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#def binaryCounter(offset):\n",
        "  \"\"\"\n",
        "  Returns a DataFrame based on the above encodings given an offset.\n",
        "  \"\"\"\n",
        "  #bit8 = (offset % 12 == 8)\n",
        "  #bit7 = (offset % 12 == 4)\n",
        "  #bit6 = (offset % 4 == 0)\n",
        "  #bit5 = (offset % 48 == 0)\n",
        "  #bit4 = (offset % 24 == 0)\n",
        "  #bit3 = (offset % 12 == 0)\n",
        "  #bit2 = (offset % 6 == 0)\n",
        "  #bit1 = (offset % 3 == 0)\n",
        "  #return pd.DataFrame(np.array([bit8, bit7, bit6, bit5, bit4, bit3, bit2, bit1])).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PNcH3hljVt29",
        "colab_type": "code",
        "outputId": "3ce25b8f-475b-4fa4-fcc6-31507b82f738",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "cell_type": "code",
      "source": [
        "binaryCounter(4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0     1     2      3      4      5      6      7\n",
              "0  False  True  True  False  False  False  False  False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "iFXGKnQuFzrw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**NOTE: THE ABOVE CODE IS INCOMPLETE UNTIL I'VE TESTED WITHOUT THESE FEATURES FIRST**"
      ]
    },
    {
      "metadata": {
        "id": "pW81R5ezF7O5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sampling The Data"
      ]
    },
    {
      "metadata": {
        "id": "lFNbUI1MyP5H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Per my past summaries of previous works, we have this process for formatting data for Keras:\n",
        "\n",
        "We have dataset $D=(X, Y)$ of \"labelled\" chord progression segments: $X = \\{X_1, X_2, ..., X_n\\}$ and $Y = \\{Y_1, Y_2, ..., Y_n\\}$, where each $X_i$ is some section of chord progression and each $Y_i$ is the corresponding melody label. My original piano matrix is of dimensions $(\\text{# timesteps}, |\\text{note range}|)$. In the 18-bit case, this is more simply $(\\text{# timesteps}, 18)$.\n",
        "\n",
        "First, we need to sample these matrices into $t$-timestep-long sequences of chord data (these are our $X_i$). We'll then label each of these with the melody information from the $t+1$ timestep. The number of samples, $S$, will be the total length of each song (in timesteps) minus $t+1$."
      ]
    },
    {
      "metadata": {
        "id": "BDXhlawYGKkh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The final data shape should be a 3D matrix of dimensions $(\\text{# samples}, \\text{time steps}, \\text{features})$. Therefore we'll just need to sample the piano and 18-biot matrices into samples without any other dimensional shifting. But *what sample sizes did my sources use?*\n",
        "* Choi - Sampled 20 characters at a time with step size 3.\n",
        "* Lackner - Seems to be 8, or 2 beats worth.\n",
        "* Hilscher - Sentence length 100 (used chars)\n",
        "\n",
        "The rest of my sources didn't really say."
      ]
    },
    {
      "metadata": {
        "id": "4W4fUUmD7nq1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Conclusion** - I think the two-beat samples of Lackner might be a good place to start, or maybe even the full four beats eventually. These would be 24 or 48 timesteps. I'd also consider sampling at an interval of 5, as an example, to decrease redundancy if training takes too long. Until I hit this wall, I'll use a step size between windows of 1. So let's get to sampling, then."
      ]
    },
    {
      "metadata": {
        "id": "tKWBqo2T7rm2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample(df, sample_length, step):\n",
        "  \"\"\"\n",
        "  Splits a given dataframe into overlapping samples each beginning the given step size apart.\n",
        "  \n",
        "  df : Pandas DataFrame\n",
        "    The DataFrame to be sliced into samples.\n",
        "  sample_length : int\n",
        "    The desired length of each sample.\n",
        "  step : int\n",
        "    The number of timesteps between where each sample begins.\n",
        "  \"\"\"\n",
        "  length = df.shape[0]\n",
        "  samples = []\n",
        "  for i in range(0, (length - sample_length - 1), step):\n",
        "    sample = df.iloc[i:i+sample_length, :]\n",
        "    samples.append(sample)\n",
        "    \n",
        "  return samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-coFnTiN87d1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Reading in the Data"
      ]
    },
    {
      "metadata": {
        "id": "1dj1sjHY9H18",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "os.chdir(\"Melodies Piano Roll\")\n",
        "!ls\n",
        "\n",
        "c_bits = glob.glob(\"*.csv\")\n",
        "#c_tokens = glob.glob(\"*.csv\")\n",
        "#m_18bits = glob.glob(\"*.csv\")\n",
        "#m_piano = glob.glob(\"*.csv\")\n",
        "\n",
        "names = []\n",
        "for c in c_bits:\n",
        "  names.append(c[:-4])\n",
        "name_indices = dict((n, i) for i, n in enumerate(names))\n",
        "\n",
        "for i, c in enumerate(m_piano):\n",
        "  df = pd.read_csv(c)\n",
        "  new_name = str(name_indices[c[:-4]]) + \".csv\"\n",
        "  df.to_csv(new_name)\n",
        "  print(i)\n",
        "  \n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6O46QH-7F3WG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The above code was used to rename all csv so they're more clearly compatible."
      ]
    },
    {
      "metadata": {
        "id": "kUW2l3AiHIMP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09239625-6cab-4469-ede7-2c44b79a4a88"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Chords Bits'  'Chords Tokens'\t'Melodies 18-bit'  'Melodies Piano Roll'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IQv0EaszHJgk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "57a3d58e-e822-46b4-c7f2-f9357232a0aa"
      },
      "cell_type": "code",
      "source": [
        "glob.glob(\"*/1.csv\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Chords Bits/1.csv',\n",
              " 'Chords Tokens/1.csv',\n",
              " 'Melodies 18-bit/1.csv',\n",
              " 'Melodies Piano Roll/1.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "BdkSZmMkKnKR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def readCSV(filename):\n",
        "  # Cleans up the .csv from all the exporting/importing.\n",
        "  df = pd.read_csv(filename)\n",
        "  df = df.drop(columns = df.columns[0:2])\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}